{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "special-cleaners",
   "metadata": {},
   "source": [
    "# Deep Dive to Deep Learning and Backpropagation with azure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-craps",
   "metadata": {},
   "source": [
    "El objetivo de este notebook es dar una introduccion a algunas utilidades que ofrece Azure machine learning, dar un ejemplo muy simple del uso practico de las redes neuronales y una breve introduccion a keras y tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-dakota",
   "metadata": {},
   "source": [
    "### Cargamos nuestro dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-delta",
   "metadata": {},
   "source": [
    "Importamos las librerias usuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abroad-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ahead-welsh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine #Importamos nuestro dataset de jugete de la libreria scikit-learn.\n",
    "\n",
    "#Descargamos nuestro dataset\n",
    "wine = load_wine()\n",
    "\n",
    "df1 = pd.DataFrame(wine.data)\n",
    "df1.columns = wine.feature_names\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-scoop",
   "metadata": {},
   "source": [
    "InformaciÃ³n sobre el dataset: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-custody",
   "metadata": {},
   "source": [
    "### Procesamiento del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-population",
   "metadata": {},
   "source": [
    "En esta parte empieza el verdadero procesamiento de los datos antes de crear nuestra red neuronal. \n",
    "\n",
    "La libreria que utilizaremos es scikit-learn la cual es la libreria standar para machine learning en python, la cual tambien tien la facilidad de hacer pipelines de preprocesamiento de datos junto con sus respectivas funcionalidades.\n",
    "\n",
    "<img src=\"imagenes/Sklearn_logo.png\" width=\"400\">\n",
    "\n",
    "\n",
    "- DocumentaciÃ³n: https://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "binary-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA #Importamos el algrotimo PCA(Principal Component Analysis) para reducciÃ³n de dimensiones\n",
    "\n",
    "#Separamos nuestro dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=42)\n",
    "\n",
    "#Standarizamos nuestro dataset\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)#Normalizamos nuestros datos z=(x-mean)/std, para que todos esten en el mismo rango.\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "#Standarizamos y reducimos las dimensiones\n",
    "#std_pca = make_pipeline(StandardScaler(), PCA(n_components=2))\n",
    "#X_train = std_pca.fit_transform(X_train)\n",
    "#X_test = std_pca.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-adobe",
   "metadata": {},
   "source": [
    "### CreaciÃ³n de modelo de deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-fraud",
   "metadata": {},
   "source": [
    "Para creaciÃ³n de nuestro modelo de deep learning utilizaremos las librerias Tensorflow y Keras las cuales trabajan juntas para facilitar la creaciÃ³n de redees neuronales.\n",
    "\n",
    "<img src=\"imagenes/keras_tf.jpeg\" width=\"300\">\n",
    "\n",
    "Imagen del libro Hands on Machine Learning with Scikit-Learn, Keras and Tensorflow por AurÃ©lien GÃ©ron.\n",
    "\n",
    "DocumentaciÃ³n:\n",
    "- Keras: https://keras.io/api/\n",
    "- Tensorflow: https://www.tensorflow.org/api_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "green-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No aseguramos que tengamos tensorflow y keras en su ultima version\n",
    "#! pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "lonely-contamination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.4.0\n",
      "TensorFlow version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow #importamos tensorflow\n",
    "from tensorflow import keras #importamos keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential #Sequential es el modelo mas simple de redes neuronales (Feedforward NNs)\n",
    "from tensorflow.keras.layers import Dense #Capa normal de deep learning totalmente conectada \n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Declaramos una semilla para que siempre nos den los mismos resultados\n",
    "tensorflow.random.set_seed(0)\n",
    "\n",
    "#Checamos las versiones de keras y tensorflow\n",
    "print('Keras version:',keras.__version__)\n",
    "print('TensorFlow version:',tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "imposed-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos aseguramos que nuestro tipo de datos sea float32 o float64\n",
    "x_train = X_train.astype('float32')\n",
    "x_test = X_test.astype('float32')\n",
    "\n",
    "# Le decimos a tensorflow que nuestras variables objetivo son categoricas\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "meaningful-robert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 283\n",
      "Trainable params: 283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Definimos nuestros parametros\n",
    "nodes = 10 # NÃºmero de nodos en nuestras capas ocultas o hidden layers\n",
    "features = len(wine.feature_names) #NÃºmero de atributos\n",
    "wine_classes = wine.target_names #NÃºmero de clases a clasificar\n",
    "\n",
    "#Creamos nuestra red neuronal\n",
    "model = Sequential()\n",
    "#Keras agrega automaticamente la capa de inputs\n",
    "model.add(Dense(nodes, input_dim=features, activation='relu')) #Hidden Layer 1\n",
    "model.add(Dense(nodes, input_dim=nodes, activation='relu')) #Hidden Layer 2\n",
    "model.add(Dense(len(wine_classes), input_dim=nodes, activation='sigmoid')) #Output layer\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-athens",
   "metadata": {},
   "source": [
    "### Entrenamos nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "running-terrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.7202 - accuracy: 0.7829 - val_loss: 0.7041 - val_accuracy: 0.8333\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7029 - accuracy: 0.7721 - val_loss: 0.6974 - val_accuracy: 0.8611\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.7952 - val_loss: 0.6906 - val_accuracy: 0.8611\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.7878 - val_loss: 0.6835 - val_accuracy: 0.8611\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.7825 - val_loss: 0.6767 - val_accuracy: 0.8611\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.7970 - val_loss: 0.6703 - val_accuracy: 0.8611\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6460 - accuracy: 0.7943 - val_loss: 0.6639 - val_accuracy: 0.8611\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.8098 - val_loss: 0.6574 - val_accuracy: 0.8611\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.8232 - val_loss: 0.6509 - val_accuracy: 0.8611\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.8589 - val_loss: 0.6448 - val_accuracy: 0.8611\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.8514 - val_loss: 0.6388 - val_accuracy: 0.8611\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.8609 - val_loss: 0.6326 - val_accuracy: 0.8611\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.8591 - val_loss: 0.6264 - val_accuracy: 0.8889\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.8147 - val_loss: 0.6206 - val_accuracy: 0.8889\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.7844 - val_loss: 0.6149 - val_accuracy: 0.8889\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.8415 - val_loss: 0.6092 - val_accuracy: 0.8889\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.8243 - val_loss: 0.6037 - val_accuracy: 0.9167\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.8821 - val_loss: 0.5982 - val_accuracy: 0.9167\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.8045 - val_loss: 0.5929 - val_accuracy: 0.9167\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.8638 - val_loss: 0.5873 - val_accuracy: 0.9167\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.8444 - val_loss: 0.5819 - val_accuracy: 0.9167\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.8565 - val_loss: 0.5768 - val_accuracy: 0.9167\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.9203 - val_loss: 0.5717 - val_accuracy: 0.9167\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.8892 - val_loss: 0.5665 - val_accuracy: 0.9167\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.8983 - val_loss: 0.5618 - val_accuracy: 0.9167\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5889 - accuracy: 0.8919 - val_loss: 0.5570 - val_accuracy: 0.9167\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.8924 - val_loss: 0.5518 - val_accuracy: 0.9167\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.8871 - val_loss: 0.5467 - val_accuracy: 0.9167\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.8706 - val_loss: 0.5417 - val_accuracy: 0.9167\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.8604 - val_loss: 0.5367 - val_accuracy: 0.9167\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.8846 - val_loss: 0.5316 - val_accuracy: 0.9167\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.8912 - val_loss: 0.5266 - val_accuracy: 0.9167\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.8807 - val_loss: 0.5218 - val_accuracy: 0.9167\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.8371 - val_loss: 0.5170 - val_accuracy: 0.9167\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.8857 - val_loss: 0.5124 - val_accuracy: 0.9167\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.9155 - val_loss: 0.5080 - val_accuracy: 0.9167\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.9130 - val_loss: 0.5032 - val_accuracy: 0.9167\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.8939 - val_loss: 0.4987 - val_accuracy: 0.9167\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.8680 - val_loss: 0.4942 - val_accuracy: 0.9167\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.9095 - val_loss: 0.4897 - val_accuracy: 0.9167\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.9235 - val_loss: 0.4855 - val_accuracy: 0.9167\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.8885 - val_loss: 0.4811 - val_accuracy: 0.9167\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.9085 - val_loss: 0.4769 - val_accuracy: 0.9167\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.8819 - val_loss: 0.4726 - val_accuracy: 0.9167\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5091 - accuracy: 0.8576 - val_loss: 0.4683 - val_accuracy: 0.9167\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.9274 - val_loss: 0.4640 - val_accuracy: 0.9167\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.9299 - val_loss: 0.4600 - val_accuracy: 0.9167\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.9518 - val_loss: 0.4559 - val_accuracy: 0.9167\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.9164 - val_loss: 0.4521 - val_accuracy: 0.9167\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.9107 - val_loss: 0.4482 - val_accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "#Derclaramos hyper-parametros del modelo\n",
    "learning_rate = 0.001 #Conviene tener un paso chico porque si no el gradiente puede brincar.\n",
    "opt = optimizers.SGD(lr=learning_rate) #Declaramos nuestro algoritmo con el cual actualizaremos los pesos. \n",
    "#opt = optimizers.Adam(lr=learning_rate) \n",
    "\n",
    "#Compilamos el modelo\n",
    "model.compile(loss='categorical_crossentropy',#Declaramos nuestra funciÃ³n de costo\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenamos nuestro modelo con 50 epocas y un \"batch\" de 10 ejemplos.\n",
    "num_epochs = 50\n",
    "history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "toxic-strand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-contract",
   "metadata": {},
   "source": [
    "Algunos recursos que pueden ayudar a entender mejor los conceptos:\n",
    "- Gradient Descent: https://www.youtube.com/watch?v=IHZwWFHWa-w\n",
    "- Cross entropy loss function: https://www.youtube.com/watch?v=6ArSys5qHAU\n",
    "- Performance metrics: https://www.youtube.com/watch?v=2osIZ-dSPGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-england",
   "metadata": {},
   "source": [
    "### EvaluaciÃ³n del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-scale",
   "metadata": {},
   "source": [
    "Graficamos las curvas de aprendizaje del set de entrenamiento y el test set.\n",
    "\n",
    "Lo que se espera es que las dos bajen juntas, en el caso contrario podrÃ­a indicar overfitting o underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "passive-identification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "epoch_nums = range(1,num_epochs+1)\n",
    "training_loss = history.history[\"loss\"]\n",
    "validation_loss = history.history[\"val_loss\"]\n",
    "fig = plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "julian-moldova",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-portland",
   "metadata": {},
   "source": [
    "Matriz de confusion.\n",
    "\n",
    "Un buen modelo tendra una diagonal bien definida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "neural-polymer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f31f6371378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class_probabilities = model.predict(x_test)\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Reds)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(wine_classes))\n",
    "plt.xticks(tick_marks, wine_classes, rotation=85)\n",
    "plt.yticks(tick_marks, wine_classes)\n",
    "plt.xlabel(\"Actual Class\")\n",
    "plt.ylabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-double",
   "metadata": {},
   "source": [
    "### Pesos Aprendidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "opposed-shipping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Weights:\n",
      " [[-0.19427498 -0.34086928  0.03731931  0.21464008 -0.06556716  0.27108136\n",
      "  -0.10377592  0.48931652  0.18152598 -0.39315462]\n",
      " [ 0.21372367  0.16797972  0.08512294 -0.1620195  -0.10042514  0.18845835\n",
      "   0.4439417   0.20865342  0.3322421  -0.42917514]\n",
      " [-0.20706645 -0.4854431   0.23847175  0.33410197  0.17825048  0.04022984\n",
      "   0.24706069 -0.433691   -0.47586763  0.23471214]\n",
      " [-0.3203244  -0.14348628 -0.20179558 -0.49982193 -0.4017728   0.3231263\n",
      "   0.18313038  0.5139824   0.41889963 -0.31696343]\n",
      " [-0.40104827  0.05145485 -0.33418703  0.03841482  0.5046187  -0.3257045\n",
      "  -0.50649387  0.11480745  0.09343772  0.29097855]\n",
      " [ 0.0729349  -0.38453066  0.43354473 -0.10808805  0.11380529 -0.30213922\n",
      "  -0.51959616 -0.17633678 -0.46544486 -0.47119406]\n",
      " [ 0.4268563   0.41080526 -0.08279347  0.09897359  0.20294936  0.12840977\n",
      "   0.33925405 -0.22943793 -0.34090707  0.0943486 ]\n",
      " [-0.08149108  0.11508285  0.42680946  0.22459619 -0.5512137  -0.19240819\n",
      "  -0.23145874 -0.43023887  0.4925478  -0.31480756]\n",
      " [ 0.19643924  0.25937447  0.32301262  0.27334946  0.29158646 -0.36495665\n",
      "   0.18348807 -0.36775655  0.07796107 -0.46196988]\n",
      " [ 0.17057174  0.00822486 -0.46256784  0.02590451  0.42300344  0.2975547\n",
      "   0.09752233 -0.09204459  0.29808086 -0.46218577]\n",
      " [ 0.17623466  0.01616114 -0.47701883  0.48684755  0.00964259 -0.09290584\n",
      "  -0.44893733  0.15563348  0.25108135 -0.06578756]\n",
      " [-0.4629747   0.06794284 -0.4024285   0.01495384  0.14217016 -0.5083983\n",
      "   0.37097207 -0.28253874 -0.07092147  0.08194739]\n",
      " [-0.39673752 -0.24769467 -0.30767152  0.35580227 -0.18682964  0.32218534\n",
      "   0.13881278  0.10498453  0.23822473  0.1786643 ]] \n",
      "Biases:\n",
      " [-0.02686139  0.00026255  0.04843452  0.08863758  0.05079981  0.00681319\n",
      " -0.01303018  0.00439983  0.03020168 -0.03944371]\n",
      "------------\n",
      "Weights:\n",
      " [[ 0.16590719 -0.2866267   0.39310044  0.20351492  0.13487144 -0.01604246\n",
      "  -0.529065    0.40679476 -0.04561323 -0.12407628]\n",
      " [ 0.5537062   0.15913936 -0.5436632   0.27343735 -0.44138578  0.44874448\n",
      "  -0.31722194  0.18158571 -0.43402162 -0.384198  ]\n",
      " [ 0.61212844  0.3880291  -0.4804251   0.11680329 -0.05731049  0.49631813\n",
      "   0.42341065  0.3097794   0.27592114 -0.22365537]\n",
      " [-0.10553217  0.3339587  -0.23301587  0.25530356  0.418712    0.54037106\n",
      "  -0.30011457 -0.5520024  -0.01642606 -0.44065183]\n",
      " [ 0.46186426  0.54403555  0.43653545  0.02505856  0.14251362  0.20455445\n",
      "   0.1286445   0.21358557 -0.4801085  -0.29197207]\n",
      " [ 0.49396947 -0.3790057   0.43360183  0.31655574 -0.25079253 -0.5282973\n",
      "   0.40103582  0.04852995  0.35939518 -0.03170262]\n",
      " [ 0.28022942 -0.11770578 -0.05262896 -0.30814767  0.15991716 -0.39671096\n",
      "  -0.16984144  0.5074291   0.33934358 -0.49729413]\n",
      " [-0.3967742  -0.20919095  0.06448212 -0.47613576 -0.20106576  0.282979\n",
      "   0.08149089  0.30338788  0.32334208 -0.24363074]\n",
      " [-0.45566636 -0.41797385 -0.40618238 -0.51691705 -0.27516288 -0.4050504\n",
      "  -0.11124685  0.28780273  0.19040887  0.2409692 ]\n",
      " [ 0.40944707 -0.26787287 -0.37179375  0.3779415  -0.32411864  0.1944435\n",
      "  -0.1952133   0.23290108 -0.33302626 -0.51532805]] \n",
      "Biases:\n",
      " [ 0.07621238  0.14909375  0.02249256 -0.04786648  0.09040544 -0.06101491\n",
      "  0.01074531  0.00553857  0.03240094 -0.00126108]\n",
      "------------\n",
      "Weights:\n",
      " [[-0.415356    0.5193401  -0.20835024]\n",
      " [ 0.58744836 -0.13565622 -0.7276397 ]\n",
      " [ 0.3094049  -0.1959604   0.09839247]\n",
      " [ 0.5283083  -0.37976342 -0.04306814]\n",
      " [ 0.329367   -0.70518595 -0.21504472]\n",
      " [ 0.10354325 -0.10313363  0.03741513]\n",
      " [ 0.6538777  -0.62428564  0.56869596]\n",
      " [-0.4325912   0.11676175  0.24149327]\n",
      " [-0.49297023 -0.36080274  0.6953195 ]\n",
      " [ 0.6530776  -0.6310395  -0.00993279]] \n",
      "Biases:\n",
      " [-0.00429649  0.16805126 -0.16375473]\n"
     ]
    }
   ],
   "source": [
    " for layer in model.layers:\n",
    "    weights = layer.get_weights()[0]\n",
    "    biases = layer.get_weights()[1]\n",
    "    print('------------\\nWeights:\\n',weights,'\\nBiases:\\n', biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-debate",
   "metadata": {},
   "source": [
    "En total se aprendieron 283 parametros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-blackberry",
   "metadata": {},
   "source": [
    "### Guardamos el Modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "technical-talent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved as models/wine-classifier.h5\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "modelFileName = 'models/wine-classifier.h5'\n",
    "model.save(modelFileName)\n",
    "del model  # deletes the existing model variable\n",
    "print('model saved as', modelFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "everyday-summer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample:[[ 0.53637204 -0.38282884  0.87353409  0.14758633 -0.07869263  0.36624231\n",
      "   0.48805986 -0.5490214   0.26266406 -0.67897214  0.77072924  1.73119782\n",
      "   0.14260936]]\n",
      "WARNING:tensorflow:9 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3205766950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "class_0\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el modelo\n",
    "model = models.load_model(modelFileName)\n",
    "\n",
    "# Tomamos un ejemplo del test set\n",
    "x_new = [X_test[10]]\n",
    "x_new = np.array(x_new)\n",
    "print ('New sample:'+str(format(x_new)))\n",
    "\n",
    "# Predecimos la nueva clase\n",
    "class_probabilities = model.predict(x_new)\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "print(wine_classes[predictions[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-particular",
   "metadata": {},
   "source": [
    "## Experimentos en Azure Machine Learning Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-auditor",
   "metadata": {},
   "source": [
    "Una de las funciones principales funciones de Azure ML studio es la capacidad de realizar experimentos, los cuales son muy utiles para los cientificos de datos porque nos dejan registrar diferentes parametros y guardar los resultados de los diferentes experimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-matthew",
   "metadata": {},
   "source": [
    "### Conectamos con nuestro workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "institutional-proceeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.22.0 to work with prueba1\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-madison",
   "metadata": {},
   "source": [
    "Lo mejor es tener el experimento como un script en casop que quieras probar con varios parametros pero en este caso no consideraremos eso.\n",
    "\n",
    "Nota: debe de haver una carpeta models en el directorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "handy-capacity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: deeplearning-experiment\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 1.1793 - accuracy: 0.3889 - val_loss: 1.1169 - val_accuracy: 0.4444\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0534 - accuracy: 0.4344 - val_loss: 0.9967 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9618 - accuracy: 0.4699 - val_loss: 0.8967 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8705 - accuracy: 0.5277 - val_loss: 0.8109 - val_accuracy: 0.6111\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7734 - accuracy: 0.6394 - val_loss: 0.7329 - val_accuracy: 0.6667\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.7643 - val_loss: 0.6657 - val_accuracy: 0.7500\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.7850 - val_loss: 0.6082 - val_accuracy: 0.8333\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.7899 - val_loss: 0.5602 - val_accuracy: 0.8889\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.8737 - val_loss: 0.5145 - val_accuracy: 0.9167\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.9004 - val_loss: 0.4734 - val_accuracy: 0.9167\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.9072 - val_loss: 0.4361 - val_accuracy: 0.9444\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.4030 - accuracy: 0.9452 - val_loss: 0.4000 - val_accuracy: 0.9444\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.9636 - val_loss: 0.3644 - val_accuracy: 0.9444\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.9441 - val_loss: 0.3310 - val_accuracy: 0.9444\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3443 - accuracy: 0.9147 - val_loss: 0.3019 - val_accuracy: 0.9444\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.2784 - accuracy: 0.9464 - val_loss: 0.2770 - val_accuracy: 0.9444\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2631 - accuracy: 0.9537 - val_loss: 0.2544 - val_accuracy: 0.9444\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2181 - accuracy: 0.9666 - val_loss: 0.2352 - val_accuracy: 0.9444\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2233 - accuracy: 0.9634 - val_loss: 0.2155 - val_accuracy: 0.9444\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.9508 - val_loss: 0.1995 - val_accuracy: 0.9444\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9705 - val_loss: 0.1845 - val_accuracy: 0.9444\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1546 - accuracy: 0.9579 - val_loss: 0.1726 - val_accuracy: 0.9444\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9844 - val_loss: 0.1617 - val_accuracy: 0.9722\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.1225 - accuracy: 0.9818 - val_loss: 0.1511 - val_accuracy: 0.9722\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1306 - accuracy: 0.9704 - val_loss: 0.1431 - val_accuracy: 0.9722\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9604 - val_loss: 0.1361 - val_accuracy: 0.9722\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9826 - val_loss: 0.1301 - val_accuracy: 0.9722\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9677 - val_loss: 0.1236 - val_accuracy: 0.9722\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9828 - val_loss: 0.1176 - val_accuracy: 0.9722\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9879 - val_loss: 0.1121 - val_accuracy: 0.9722\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9781 - val_loss: 0.1080 - val_accuracy: 0.9722\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0701 - accuracy: 0.9840 - val_loss: 0.1037 - val_accuracy: 0.9722\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9853 - val_loss: 0.1002 - val_accuracy: 0.9722\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 0.9691 - val_loss: 0.0969 - val_accuracy: 0.9722\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9729 - val_loss: 0.0937 - val_accuracy: 0.9722\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9805 - val_loss: 0.0910 - val_accuracy: 0.9722\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9918 - val_loss: 0.0877 - val_accuracy: 0.9722\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9858 - val_loss: 0.0847 - val_accuracy: 0.9722\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9706 - val_loss: 0.0819 - val_accuracy: 0.9722\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9987 - val_loss: 0.0797 - val_accuracy: 0.9722\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9958 - val_loss: 0.0769 - val_accuracy: 0.9722\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9850 - val_loss: 0.0741 - val_accuracy: 0.9722\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9977 - val_loss: 0.0719 - val_accuracy: 0.9722\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9941 - val_loss: 0.0684 - val_accuracy: 0.9722\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 0.9722\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9722\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9722\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 0.9722\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9722\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9722\n",
      "model saved as models/wine-classifier.h5\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from azureml.core import Experiment\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace=ws, name=\"deeplearning-experiment\")\n",
    "\n",
    "# Start logging data from the experiment, obtaining a reference to the experiment run\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "#Descargamos nuestro dataset\n",
    "wine = load_wine()\n",
    "\n",
    "df1 = pd.DataFrame(wine.data)\n",
    "df1.columns = wine.feature_names\n",
    "\n",
    "#Separamos nuestro dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=42)\n",
    "\n",
    "#Standarizamos nuestro dataset\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)#Normalizamos nuestros datos z=(x-mean)/std, para que todos esten en el mismo rango.\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# Declaramos una semilla para que siempre nos den los mismos resultados\n",
    "tensorflow.random.set_seed(0)\n",
    "\n",
    "\n",
    "# Nos aseguramos que nuestro tipo de datos sea float32 o float64\n",
    "x_train = X_train.astype('float32')\n",
    "x_test = X_test.astype('float32')\n",
    "\n",
    "# Le decimos a tensorflow que nuestras variables objetivo son categoricas\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "\n",
    "# Definimos nuestros parametros\n",
    "nodes = 10 # NÃºmero de nodos en nuestras capas ocultas o hidden layers\n",
    "features = len(wine.feature_names) #NÃºmero de atributos\n",
    "wine_classes = wine.target_names #NÃºmero de clases a clasificar\n",
    "\n",
    "#Guardamos el numero de nodos\n",
    "run.log('NÃºmero de Nodos',nodes)\n",
    "\n",
    "\n",
    "#Creamos nuestra red neuronal\n",
    "model = Sequential()\n",
    "#Keras agrega automaticamente la capa de inputs\n",
    "model.add(Dense(nodes, input_dim=features, activation='relu')) #Hidden Layer 1\n",
    "model.add(Dense(nodes, input_dim=nodes, activation='relu')) #Hidden Layer 2\n",
    "model.add(Dense(len(wine_classes), input_dim=nodes, activation='sigmoid')) #Output layer\n",
    "\n",
    "#Derclaramos hyper-parametros del modelo\n",
    "learning_rate = 0.001 #Conviene tener un paso chico porque si no el gradiente puede brincar.\n",
    "#opt = optimizers.SGD(lr=learning_rate) #Declaramos nuestro algoritmo con el cual actualizaremos los pesos. \n",
    "opt = optimizers.Adam(lr=learning_rate) \n",
    "optimizador = \"Adam\"\n",
    "\n",
    "#Guardamos el learning rate y el nombre del optimizador\n",
    "run.log('Learning Rate',learning_rate)\n",
    "run.log('Optimizador',optimizador)\n",
    "\n",
    "#Compilamos el modelo\n",
    "model.compile(loss='categorical_crossentropy',#Declaramos nuestra funciÃ³n de costo\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenamos nuestro modelo con 50 epocas y un \"batch\" de 10 ejemplos.\n",
    "num_epochs = 50\n",
    "history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=10, validation_data=(x_test, y_test))\n",
    "\n",
    "#Creamos un diccionario con informaciÃ³n del entrenamiento y lo guardamos\n",
    "historia = {\n",
    "    \"training_loss\": history.history[\"loss\"],\n",
    "    \"training_accuracy\": history.history[\"accuracy\"],\n",
    "    \"val_loss\": history.history[\"val_loss\"],\n",
    "    \"val_accuracy\": history.history[\"val_accuracy\"]\n",
    "}\n",
    "run.log_table(\"training_info_by_epochs\", historia)\n",
    "\n",
    "# Guardamos el modelo\n",
    "modelFileName = 'models/wine-classifier.h5'\n",
    "model.save(modelFileName)\n",
    "del model  # elimina el anterior\n",
    "print('model saved as', modelFileName)\n",
    "\n",
    "\n",
    "# Terminamos el experimento\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-distinction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
